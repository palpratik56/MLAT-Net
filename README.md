
# ğŸ§  MLAT-Net: A Novel Hybrid Version of Multilevel Attention with Transformer for Medical Image Segmentation

> **Author:** Pratik Pal
> **Degree:** M.Tech in Computer & Systems Sciences
> **Institution:** Jawaharlal Nehru University (JNU), New Delhi, India
> **Supervisor:** Dr. Sachin B. Jadhav
> ğŸ“§ Email: [pratik25_scs@jnu.ac.in](mailto:pratik25_scs@jnu.ac.in)

---

## ğŸ” Project Overview

**MLAT-Net** is a hybrid deep learning architecture combining **U-Net-style CNN encoders** with **Transformer-based self-attention modules**. It is designed for **robust and generalizable medical image segmentation**, capable of capturing both **long-range dependencies** and **fine-grained spatial features**.

The network has been validated on **ISIC-2018**, **Kvasir-SEG**, and **CVC-ClinicDB**, segmenting polyps, lesions, and critical regions across dermoscopy, endoscopy, and colonoscopy images.

---

## ğŸ§  Architecture: MLAT-Net

MLAT-Net follows an **encoder-decoder backbone** with enhanced multi-level attention.

### ğŸ”§ Key Components

* **Self-Aware Attention (SAA) Module**

  * ğŸŒ **Transformer Self-Attention (TSA):** Captures global semantic context
  * ğŸ§­ **Global Spatial Attention (GSA):** Enhances spatial relationships

* **Multi-Scale Dense Skip Connections**
  Combines features across resolutions for improved boundary segmentation.

* **Double Ablation Design**

  * Pooling: `Max` vs `Average`
  * Optimizers: `Adam`, `RMSProp`, `Adagrad`, `SGD`

### ğŸ§¬ Input / Output

* **Input:** `(256 Ã— 256 Ã— 3)` RGB medical image

* **Output:** `(256 Ã— 256 Ã— 1)` binary segmentation mask

* **Decoder Feature Maps:** Captured at each upsampling stage for visualization and analysis

---

## ğŸ§ª Datasets Used

| Dataset      | Modality    | Images | Task                             |
| ------------ | ----------- | ------ | -------------------------------- |
| ISIC-2018    | Dermoscopy  | 2,596  | Skin lesion segmentation         |
| Kvasir-SEG   | Endoscopy   | 1,000  | Gastrointestinal polyp detection |
| CVC-ClinicDB | Colonoscopy | 612    | Polyp detection                  |

---

## ğŸ“ˆ Results Summary

### Multi-Split Validation (80:20, 70:30, 60:40)

| Dataset      | Optimizer | Dice (mean Â± std) | IoU (mean Â± std) | Notes                                        |
| ------------ | --------- | ----------------- | ---------------- | -------------------------------------------- |
| ISIC-2018    | Adam      | 0.910 Â± 0.006     | 0.840 Â± 0.008    | Best performance on skin lesion segmentation |
| Kvasir-SEG   | Adam      | 0.790 Â± 0.007     | 0.660 Â± 0.009    | Stable generalization                        |
| CVC-ClinicDB | RMSProp   | 0.900 Â± 0.005     | 0.820 Â± 0.006    | Robust boundary detection                    |

ğŸ“Œ MLAT-Net consistently outperforms baseline models (U-Net, Attention U-Net, TransUNet) across **Dice**, **IoU**, and **Recall**, with superior generalization across modalities.

---

## ğŸ§ª Experimental Setup

* **Input Resolution:** 256 Ã— 256
* **Batch Size:** 16 (scaled for multi-GPU)
* **Train/Test Splits:** 80:20, 70:30, 60:40
* **Epochs:** 50
* **Learning Rate:** 0.001 (step decay Ã—0.5 every 20 epochs)
* **Hardware:** Tesla T4 / A100 GPUs

### âš™ï¸ Optimizers Evaluated

| Optimizer | Momentum / Betas |
| --------- | ---------------- |
| Adam      | Î²â‚=0.9, Î²â‚‚=0.999 |
| RMSProp   | 0.95             |
| Adagrad   | -                |
| SGD       | 0.85 / 0.95      |

---

## ğŸ“Š Comparative Evaluation with SOTA

| Model        | Dataset      | Dice (%) | IoU (%) | Accuracy (%) | Recall (%) | Precision (%) |
| ------------ | ------------ | -------- | ------- | ------------ | ---------- | ------------- |
| **MLAT-Net** | ISIC-2018    | 90.78    | 64.10   | 94.89        | 87.89      | 93.63         |
| DoubleU-Net  | ISIC-2018    | 89.62    | 82.12   | 93.87        | 87.00      | 94.59         |
| ResUNet++    | Kvasir-SEG   | 79.97    | 79.56   | 94.57        | 70.83      | 94.64         |
| TransUNet    | CVC-ClinicDB | 93.50    | 88.70   | -            | -          | -             |
| **MLAT-Net** | CVC-ClinicDB | 86.88    | 77.23   | 97.77        | 83.66      | 90.78         |

---

## ğŸŒ Visual Results

### Example Predictions

![CVC Predictions](results/CVC_predictions_adam_max.png)
![ISIC Predictions](results/ISIC_predictions_sgd_avg.png)

### Decoder Feature Maps Across Stages

![Decoder Maps Kvasir](results/MaxPooling/Kvasir_decoder_maps_RMSprop.png)
![Decoder Maps CVC](results/CVC_decoder_maps_Adam.png)

ğŸ“Œ Feature maps illustrate how MLAT-Net captures **progressively refined semantic and spatial information** at each decoder stage.

---

## ğŸ” Limitations & Future Work

* ğŸ¢ High computational cost due to multi-level attention
* ğŸ”„ Rare channel mismatches in decoder
* âš™ï¸ Not yet optimized for 3D medical imaging

### ğŸš€ Future Enhancements

* Incorporate **skip-attention** and **adaptive encoding**
* Extend to **volumetric (3D) imaging** like MRI and CT
* Optimize for **real-time clinical inference**

---

## ğŸ“š References

* [TransUNet: arXiv:2102.04306](https://arxiv.org/abs/2102.04306)
* [DoubleU-Net](https://doi.org/10.1109/CBMS49503.2020.00111)
* [ISIC-2018 Dataset](https://arxiv.org/abs/1902.03368)
* [Kvasir-SEG Dataset](https://doi.org/10.1007/978-3-030-37734-2_37)
* [CVC-ClinicDB Dataset](https://doi.org/10.1016/j.media.2013.03.001)
